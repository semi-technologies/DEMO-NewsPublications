{"id": "1803d83e-8383-3989-a713-f0fd07a2433e", "title": "'It's the screams of the damned!' The eerie AI world of deepfake music", "url": "https://www.theguardian.com/music/2020/nov/09/deepfake-pop-music-artificial-intelligence-ai-frank-sinatra", "summary": "\u201cThe screams of the damned\u201d reads one comment below that Sinatra sample; \u201cSOUNDS FUCKING DEMONIC\u201d reads another.\nDeepfake music is set to have wide-ranging ramifications for the music industry as more companies apply algorithms to music.\nNumerous startups, such as Amper Music, produce custom, AI-generated music for media content, complete with global copyright.\nIf you didn\u2019t want to pay the market rate for using an established artist\u2019s music in a film, TV show or commercial, you could create your own imitation.\nStreaming services could, meanwhile, pad out genre playlists with similar sounding AI artists who don\u2019t earn royalties, thereby increasing profits.", "paragraphs": ["\u2018It\u2019s Christmas time! It\u2019s hot tub time!\u201d sings Frank Sinatra. At least, it sounds like him. With an easy swing, cheery bonhomie, and understated brass and string flourishes, this could just about pass as some long lost Sinatra demo. Even the voice \u2013 that rich tone once described as \u201call legato and regrets\u201d \u2013 is eerily familiar, even if it does lurch between keys and, at times, sounds as if it was recorded at the bottom of a swimming pool.", "The song in question not a genuine track, but a convincing fake created by \u201cresearch and deployment company\u201d OpenAI, whose Jukebox project uses artificial intelligence to generate music, complete with lyrics, in a variety of genres and artist styles. Along with Sinatra, they\u2019ve done what are known as \u201cdeepfakes\u201d of Katy Perry, Elvis, Simon and Garfunkel, 2Pac, C\u00e9line Dion and more. Having trained the model using 1.2m songs scraped from the web, complete with the corresponding lyrics and metadata, it can output raw audio several minutes long based on whatever you feed it. Input, say, Queen or Dolly Parton or Mozart, and you\u2019ll get an approximation out the other end.", "\u201cAs a piece of engineering, it\u2019s really impressive,\u201d says Dr Matthew Yee-King, an electronic musician, researcher and academic at Goldsmiths. (OpenAI declined to be interviewed.) \u201cThey break down an audio signal into a set of lexemes of music \u2013 a dictionary if you like \u2013 at three different layers of time, giving you a set of core fragments that is sufficient to reconstruct the music that was fed in. The algorithm can then rearrange these fragments, based on the stimulus you input. So, give it some Ella Fitzgerald for example, and it will find and piece together the relevant bits of the \u2018dictionary\u2019 to create something in her musical space.\u201d", "Admirable as the technical achievement is, there\u2019s something horrifying about some of the samples, particularly those of artists who have long since died \u2013 sad ghosts lost in the machine, mumbling banal cliches. \u201cThe screams of the damned\u201d reads one comment below that Sinatra sample; \u201cSOUNDS FUCKING DEMONIC\u201d reads another. We\u2019re down in the Uncanny Valley.", "Deepfake music is set to have wide-ranging ramifications for the music industry as more companies apply algorithms to music. Google\u2019s Magenta Project \u2013 billed as \u201cexploring machine learning as a tool in the creative process\u201d \u2013 has developed several open source APIs that allow composition using entirely new, machine-generated sounds, or human-AI co-creations. Numerous startups, such as Amper Music, produce custom, AI-generated music for media content, complete with global copyright. Even Spotify is dabbling; its AI research group is led by Fran\u00e7ois Pachet, former head of Sony Music\u2019s computer science lab.", "It\u2019s not hard to foresee, though, how such deepfakes could lead to ethical and intellectual property issues. If you didn\u2019t want to pay the market rate for using an established artist\u2019s music in a film, TV show or commercial, you could create your own imitation. Streaming services could, meanwhile, pad out genre playlists with similar sounding AI artists who don\u2019t earn royalties, thereby increasing profits. Ultimately, will streaming services, radio stations and others increasingly avoid paying humans for music?", "Legal departments in the music industry are following developments closely. Earlier this year, Roc Nation filed DMCA takedown requests against an anonymous YouTube user for using AI to mimic Jay-Z\u2019s voice and cadence to rap Shakespeare and Billy Joel. (Both are incredibly realistic.) \u201cThis content unlawfully uses an AI to impersonate our client\u2019s voice,\u201d said the filing. And while the videos were eventually reinstated \u201cpending more information from the claimant\u201d, the case \u2013 the first of its kind \u2013 rumbles on.", "Jay\u2013Z, who saw an AI version of himself rapping Shakespeare and Billy Joel. Illustration: Guardian Design/wireimage", "Roc Nation declined to comment on the legal implications of AI impersonation, as did several other major labels contacted by the Guardian: \u201cAs a public company, we have to exercise caution when discussing future facing topics,\u201d said one anonymously. Even UK industry body the BPI refused to go on the record with regard to how the industry will deal with this brave new world and what steps might be taken to protect artists and the integrity of their work. The IFPI, an international music trade body, did not respond to emails.", "Perhaps the reason is, in the UK at least, there\u2019s a worry that there\u2019s not actually a basis for legal protection. \u201cWith music there are two separate copyrights,\u201d says Rupert Skellett, head of legal for Beggars Group, which encompasses indie labels 4AD, XL, Rough Trade and more. \u201cOne in the music notation and the lyrics \u2013 ie the song \u2013 and a separate one in the sound recording, which is what labels are concerned with. And if someone hasn\u2019t used the actual recording\u201d \u2013 if they\u2019ve created a simulacrum using AI \u2013 \u201cyou\u2019d have no legal action against them in terms of copyright with regards to the sound recording.\u201d", "There\u2019d be a potential cause of action with regards to \u201cpassing off\u201d the recording, but, says Skellett, the burden of proof is onerous, and such action would be more likely to succeed in the US, where legal protections exist against impersonating famous people for commercial purposes, and where plagiarism cases like Marvin Gaye\u2019s estate taking on Blurred Lines have succeeded. UK law has no such provisions or precedents, so even the commercial exploitation of deepfakes, if the creator was explicit about their nature, might not be actionable. \u201cIt would depend on the facts of each case,\u201d Skellett says.", "Having David Bowie sing whatever you like \u2013 it's an extraordinary power and responsibility Mat Dryhurst", "Some, however, are excited by the creative possibilities. \u201cIf you\u2019ve got a statistical model of millions of songs, you can ask the algorithm: what haven\u2019t you seen?\u201d says Yee-King. \u201cYou can find that blank space, and then create something new.\u201d Mat Dryhurst, an artist and podcaster who has spent years researching and working with AI and associated technology, says: \u201cThe closest analogy we see is to sampling. These models allow a new dimension of that, and represent the difference between sampling a fixed recording of Bowie\u2019s voice and having Bowie sing whatever you like \u2013 an extraordinary power and responsibility.\u201d", "Deepfakes also pose deeper questions: what makes a particular artist special? Why do we respond to certain styles or types of music, and what happens when that can be created on demand? Yee-King imagines machines able to generate the perfect piece of music for you at any time, based on settings that you select \u2013 something already being pioneered by the startup Endel \u2013 as well as pop stars using an AI listening model to predict which songs will be popular or what different demographics respond to. \u201cJust feeding people an optimised stream of sound,\u201d he says, \u201cwith artists taken out of the loop completely.\u201d", "But if we lose all sense of emotional investment in what artists do \u2013 and in the human side of creation \u2013 we will lose something fundamental to music. \u201cThese systems are trained on human expression and will augment it,\u201d says Dryhurst. \u201cBut the missing piece of the puzzle is finding ways to compensate people, not replace them.\u201d"], "authors": ["Derek Robertson"], "keywords": ["deepfake", "sinatra", "ai", "recording", "world", "artists", "screams", "damned", "eerie", "voice", "legal", "music", "using", "piece", "sounds"], "pubDate": "2020-11-09T00:00:00", "publicationId": "c9a0e53b-93fe-38df-a6ea-4c8ff4501783"}